{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will plot the distribution of V1 cell responses to natural images. The data is 2P calcium responses in the mouse brain, from the Allen Brain Observatory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# First load the data for a sample mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all cre lines:\n",
      "\n",
      "[u'Cux2-CreERT2', u'Emx1-IRES-Cre', u'Nr5a1-Cre', u'Rbp4-Cre', u'Rbp4-Cre_KL100', u'Rorb-IRES2-Cre', u'Scnn1a-Tg3-Cre']\n",
      "4\n",
      "Experiment container info:\n",
      "{'session_type': u'three_session_B', 'age_days': 86.0, 'imaging_depth': 375, 'experiment_container_id': 511510758, 'targeted_structure': u'VISp', 'cre_line': u'Rbp4-Cre', 'id': 509600709}\n"
     ]
    }
   ],
   "source": [
    "#load data (V1, natural image responses) for a sample mouse\n",
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as cpickle\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "import allensdk.brain_observatory.stimulus_info as stim_info\n",
    "\n",
    "\n",
    "#sets the drive path of hard-disk containing observatory data, based on current OS\n",
    "if platform.system()=='Windows':\n",
    "    drive_path = 'g:/'\n",
    "else:\n",
    "    drive_path = '/Volumes/Brain2016 3/'\n",
    "\n",
    "manifest_path = os.path.join(drive_path, 'BrainObservatory/manifest.json')\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_path)\n",
    "\n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print(\"all cre lines:\\n\")\n",
    "print(cre_lines)\n",
    "\n",
    "# find all experiment containers that are from V1 and have natural gratings, and choose 1\n",
    "rbp4_ecs = boc.get_experiment_containers(targeted_structures=['VISp'],cre_lines=['Rbp4-Cre'])\n",
    "\n",
    "container_id = rbp4_ecs[1]['id']\n",
    "print len(rbp4_ecs)\n",
    "\n",
    "exp = boc.get_ophys_experiments(experiment_container_ids=[container_id], \n",
    "                                stimuli=[stim_info.NATURAL_SCENES])[0]\n",
    "\n",
    "\n",
    "print('Experiment container info:')\n",
    "print exp\n",
    "\n",
    "# get the dff traces, and the stimulus, and pull out the raw dff traces in case we need these later\n",
    "data_set = boc.get_ophys_experiment_data(exp['id'])\n",
    "specimens=data_set.get_cell_specimen_ids()\n",
    "timestamps, traces = data_set.get_dff_traces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stimulus info\n",
    "# there are 118 (0-117) natural images. images were luminance matched, contrast-normalized, and resized.\n",
    "# each image was presented for 250 ms, with no inter-image gray period\n",
    "# each image was presented 50 times, in random order\n",
    "# there was a blank sweep roughly once every 100 images. this is coded as a -1\n",
    "# these 118*50=5900+59 images were split across three sessions\n",
    "\n",
    "# pull out the stim info\n",
    "stim_table = data_set.get_stimulus_table('natural_scenes') #table with image index and start and end times of each trial\n",
    "num_trials = np.shape(stim_table)[0]\n",
    "image_id = stim_table.frame; # this is the index of the image\n",
    "num_images = 119;\n",
    "\n",
    "# to acces the response during a particular trial, you would call\n",
    "cell_loc=0\n",
    "trial_loc=0\n",
    "sample_trace = traces[cell_loc,stim_table.start[trial_loc]-28:stim_table.end[trial_loc]+28] # the added second before and\n",
    "                                                                        # after the stimulus are to match\n",
    "                                                                        # the allenSDK's definition of sweep response\n",
    "\n",
    "    \n",
    "mean_responses=[]\n",
    "for i in range(num_trials):\n",
    "    mean_responses.append(np.mean(traces[:,stim_table.start[i]-28:stim_table.end[i]+28],axis=1))\n",
    "\n",
    "\n",
    "mean_responses = np.squeeze(np.array(mean_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the mean trial responses are already pre-calculated in allenSDK, so we'll just use those instead of using the code above\n",
    "# to extract single traces and calculating a trial average. But remember that the traces extracted from the NWB (as above) will \n",
    "# have a global (experiment-wide) dff whereas the traces calculated from the SDK will have a local dff. See sweep-response-test\n",
    "# notebook. This shouldn't  produce huge differences in the sparicity stats, so we'll just use the allenSDK values.\n",
    "\n",
    "\n",
    "# For each trial, the Î”F/F for each cell was calculated using the mean fluorescence of the preceding 1 second\n",
    "# as the baseline Fo.\n",
    "\n",
    "# The mean response to each image presentation was defined as the mean change in dff during the 0.5 second period \n",
    "# following the start of the image presentation compared to the 1 second preceding the image presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pre-calculated trials and trial statisics from the allenSDK module\n",
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "# allensdk.brain_observatory.natural_scenes.NaturalScenes(data_set, **kwargs)[source]\n",
    "ns = NaturalScenes(data_set)\n",
    "print(\"done analyzing natural scenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "results_file='sample_data.pkl'\n",
    "f=open(results_file,\"wb\")\n",
    "cpickle.dump(data_set, f,protocol=cpickle.HIGHEST_PROTOCOL)\n",
    "cpickle.dump(ns, f,protocol=cpickle.HIGHEST_PROTOCOL)\n",
    "cpickle.dump(stim_table, f,protocol=cpickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or, skip to here and just load the data saved after running above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as cpickle\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "import allensdk.brain_observatory.stimulus_info as stim_info\n",
    "\n",
    "# load the data\n",
    "results_file='sample_data.pkl'\n",
    "print 'loading saved file'\n",
    "print results_file\n",
    "f = open(results_file, \"rb\")\n",
    "data_set = cpickle.load(f)\n",
    "ns = cpickle.load(f)\n",
    "stim_table = cpickle.load(f)\n",
    "f.close()\n",
    "#and calculate other quick things we'll need\n",
    "\n",
    "num_trials = np.shape(stim_table)[0]\n",
    "image_id = stim_table.frame; # this is the index of the image\n",
    "num_images = 119;\n",
    "\n",
    "# to acces the response during a particular trial, you would call\n",
    "cell_loc=0\n",
    "trial_loc=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fc12d411a1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# to get the sweep response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrial_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'trial_responses is a dataframe of size'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_responses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# to get the sweep response for a particular cell and trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ns' is not defined"
     ]
    }
   ],
   "source": [
    "# to get the sweep response\n",
    "trial_responses = ns.sweep_response\n",
    "print 'trial_responses is a dataframe of size' +np.str(np.shape(trial_responses))\n",
    "\n",
    "# to get the sweep response for a particular cell and trial\n",
    "sample_response = trial_responses[str(cell_loc)].iloc[trial_loc] \n",
    "print ('sample response is a vector of size ' +np.str(np.shape(sample_response))+' as it includes 1 sec before/after stim')\n",
    "\n",
    "# to get the mean trial response \n",
    "trial_means = ns.mean_sweep_response\n",
    "print ('trial_means is a dataframe of size ' +np.str(np.shape(trial_means)))\n",
    "\n",
    "# to get the mean sweep response for a particular cell and trial\n",
    "sample_mean = trial_means[str(cell_loc)].iloc[trial_loc] \n",
    "print ('sample_mean is a vector of size ' +np.str(np.shape(sample_mean)))\n",
    "\n",
    "\n",
    "# We can also get the mean triaal responses averaged over all 50 presentation of the same image using ns.responses\n",
    "# The response property of the stimulus-specific analysis objects is 3-D array organized with the following dimensions:\n",
    "# 0: num. number of natural scene frames (118+blank)\n",
    "# 1: num. cells + 1 (running speed)\n",
    "# 2: 0=response mean, 1=response standard error of the mean, 2=number of signficant trials\n",
    "\n",
    "# to get mean trial response averaged over all 50 presentations of an image\n",
    "mean_over_image = ns.response[:,cell_loc,0] #outputs a 119x1 vector of mean resonse over each image\n",
    "\n",
    "print '\\nyou can get the mean response averaged over all 50 repeats of an image using the ns.response module'\n",
    "\n",
    "#The peak property of the analysis object is a Pandas DataFrame of computed response metrics.\n",
    "# For natural scences this includes:\n",
    "\n",
    "# or you can just print the values for a particular cell\n",
    "specimen_id = specimens[0]\n",
    "specimen_ids = data_set.get_cell_specimen_ids()\n",
    "cell_loc = np.argwhere(specimen_ids==specimen_id)[0][0]\n",
    "\n",
    "\n",
    "print '\\nyou can also get additional parameters using the ns.peak module'\n",
    "print ns.peak.loc[cell_loc].head()\n",
    "\n",
    "# we weon't use these here. I'm just posting the code here for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the response distribution one cell to all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "\n",
    "cell_loc=0\n",
    "\n",
    "######################### plot the mean response of one cell to all unique images (mean over 50 repeats of each image)\n",
    "mean_cell = np.squeeze(ns.response[:,cell_loc,0])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "axs[0].scatter(np.arange(0,119,1), mean_cell, color='k')\n",
    "axs[0].set_xlabel('Image index')\n",
    "axs[0].set_ylabel('Mean dff response (50 repeats)')\n",
    "axs[0].set_title('response of cell to all unique images')\n",
    "\n",
    "axs[1].hist(mean_cell)\n",
    "axs[1].set_ylabel('Number of responses')\n",
    "axs[1].set_xlabel('Mean dff response (50 repeats)')\n",
    "axs[1].set_title(' responses of cell to all unique images')\n",
    "plt.tick_params(axis='y', which='both', top='off')\n",
    "\n",
    "#measure the kurtosis of the histogram\n",
    "k1=stats.kurtosis(mean_cell, axis=0, fisher=True, bias=True)\n",
    "print 'kurtosis of distribution of responses, averaged over all unique images is '+ np.str(k1)\n",
    "\n",
    "####################### now plot the response of one cell to all images\n",
    "\n",
    "mean_cell = trial_means[str(cell_loc)]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "axs[0].scatter(np.arange(0,num_trials,1), mean_cell, color='k')\n",
    "axs[0].set_xlabel('Image index')\n",
    "axs[0].set_ylabel('dff response')\n",
    "axs[0].set_title('response of cell to all images')\n",
    "\n",
    "axs[1].hist(mean_cell)\n",
    "axs[1].set_ylabel('Number of responses')\n",
    "axs[1].set_xlabel('dff response ')\n",
    "axs[1].set_title('responses of cell to all images')\n",
    "plt.tick_params(axis='y', which='both', top='off')\n",
    "\n",
    "#measure the kurtosis of the histogram\n",
    "k1=stats.kurtosis(mean_cell, axis=0, fisher=True, bias=True)\n",
    "print 'kurtosis of distribution of responses to all images is '+ np.str(k1)\n",
    "\n",
    "####################### now see if you can get back the top plot (mean over each image), from the trial responses\n",
    "#### the answer is yes so I'm going to comment this section out\n",
    "#mean_over_image=[]\n",
    "#for i in range(num_images):\n",
    "#    temp_ind=np.flatnonzero(image_id==i-1)\n",
    "#    mean_over_image.append(np.mean(trial_means[str(cell_loc)].iloc[temp_ind]))\n",
    "\n",
    "#print np.shape(mean_over_image)\n",
    "\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#axs = axs.ravel()\n",
    "\n",
    "#axs[0].scatter(np.arange(0,num_images,1), mean_over_image, color='k')\n",
    "#axs[0].set_xlabel('Image index')\n",
    "#axs[0].set_ylabel('Mean dff response (50 repeats)')\n",
    "#axs[0].set_title('response of cell to all unique images')\n",
    "\n",
    "#axs[1].hist(mean_over_image)\n",
    "#axs[1].set_ylabel('Number of responses')\n",
    "#axs[1].set_xlabel('Mean dff response (50 repeats)')\n",
    "#axs[1].set_title(' responses of cell to all unique images')\n",
    "#plt.tick_params(axis='y', which='both', top='off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now define the sparsity of each cell's respones using three metrics:\n",
    "Both metrics will be calculated based on the average (over 50 repeats) response to each unique image.\n",
    "# 1) kurtosis of distribution of average response over 50 repeats. Higher values       indicate higher sparsity\n",
    "# 2) fraction of images that produce a resonse 1SD above or below mean, relative to fraction (0.34) for normal distribution. Higher values indicate higher sparsity.\n",
    "\n",
    "# 3) fraction of images that produce a resonse > +/-2% dff.\n",
    "\n",
    "# We'll see which metric peforms best.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sparsity index (k) for a normal distribution should be 0, our code gives: -0.0927765816005\n",
      "the sparsity index (v) for a normal distribution should be 0, our code gives: 0.023\n",
      "the sparsity index (f) does not make sense for a non-dff data so we will not test here\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# define the indices \n",
    "def get_indk(data):\n",
    "    return stats.kurtosis(data, axis=0, fisher=True, bias=True)\n",
    "\n",
    "def get_indv(data):\n",
    "    num_images = np.shape(data)[0]\n",
    "    mean_resp_cell = np.mean(data)\n",
    "    std_resp_cell = np.std(data)\n",
    "    threshh = mean_resp_cell+std_resp_cell\n",
    "    threshl = mean_resp_cell-std_resp_cell\n",
    "    high_tail_cells = len(np.flatnonzero((data>threshh)))\n",
    "    low_tail_cells = len(np.flatnonzero((data<threshl)))\n",
    "    sprs_indv = 0.34-(high_tail_cells+low_tail_cells)/float(num_images)\n",
    "    return sprs_indv\n",
    "\n",
    "#fixed threshold of 2%dff response (not a good metric, we won't use)\n",
    "def get_indf(data): \n",
    "    num_images = np.shape(data)[0]\n",
    "    return 1-(len(np.flatnonzero(np.abs(data>2)))/float(num_images))\n",
    "\n",
    "# test these indices on a distribution with known kurtosis (normal distribution has kurtosis of 0)\n",
    "data = np.random.normal(0,1,1000) #data form normal distribution\n",
    "\n",
    "sprs_indk = get_indk(data)\n",
    "sprs_indv = get_indv(data)\n",
    "sprs_indf = get_indf(data)\n",
    "                 \n",
    "print 'the sparsity index (k) for a normal distribution should be 0, our code gives: ' +np.str(sprs_indk)\n",
    "print 'the sparsity index (v) for a normal distribution should be 0, our code gives: ' +np.str(sprs_indv)\n",
    "print 'the sparsity index (f) does not make sense for a non-dff data so we will not test here'                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now get the sparsity metric for all cells in this mouse and plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_cells = np.shape(ns.response[:,:,0])[1]-1\n",
    "\n",
    "sprs_indk = []\n",
    "sprs_indf = []\n",
    "sprs_indv = []\n",
    "for i in range(num_cells):\n",
    "    data = np.squeeze(ns.response[:,i,0])\n",
    "    sprs_indk.append(get_indk(data))\n",
    "    sprs_indv.append(get_indv(data))\n",
    "    sprs_indf.append(get_indf(data))\n",
    "\n",
    "\n",
    "    \n",
    "# now plot\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axs = axs.ravel()\n",
    "\n",
    "axs[0].hist(sprs_indk)\n",
    "axs[0].set_ylabel('Number of neurons')\n",
    "axs[0].set_xlabel('Sparsity Index (kurtosis)')\n",
    "plt.tick_params(axis='y', which='both', top='off')\n",
    "\n",
    "axs[1].hist(sprs_indv)\n",
    "axs[1].set_xlabel('Sparsity Index (variable threshold)')\n",
    "plt.tick_params(axis='y', which='both', top='off')\n",
    "\n",
    "axs[2].hist(sprs_indf)\n",
    "axs[2].set_xlabel('Sparsity Index (fixed threshold)')\n",
    "plt.tick_params(axis='y', which='both', top='off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We'll move forward with the first two metrics.\n",
    "Looks like the kurtosis-based and variable threshold indices produce more or less similar results, but the last index based on fixed threshold doesn't. It also reports that the majority of cells are highly sparse, which is in disagreement with the other two metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the first two metrics against each other to see their correlation\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "plt.scatter(sprs_indk,sprs_indv)\n",
    "plt.xlabel('Sparsity Index (kurtosis)')\n",
    "plt.ylabel('Sparsity Index (variable threshold)')\n",
    "plt.title('Comparison of first two metrics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now get the mean sparsity metric averaged over each mouse, for all transgenic mice in V1, and plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cux2-CreERT2\n",
      "511510736\n",
      "511510884\n",
      "511510667\n",
      "511510855\n",
      "511510650\n",
      "511509529\n",
      "511510927\n",
      "511510670\n",
      "511507650\n",
      "511510718\n",
      "511510779\n",
      "511510699\n",
      "511510736\n",
      "511510884\n",
      "511510667\n",
      "511510855\n",
      "511510650\n",
      "524691282\n",
      "511509529\n",
      "511510927\n",
      "511510670\n",
      "527550471\n",
      "530243910\n",
      "511507650\n",
      "511510718\n",
      "528959519\n",
      "511510779\n",
      "511510699\n",
      "511510736\n",
      "511510884\n",
      "511510667\n",
      "511510855\n",
      "511510650\n",
      "524691282\n",
      "511509529\n",
      "511510927\n",
      "511510670\n",
      "527550471\n",
      "530243910\n",
      "511507650\n",
      "511510718\n",
      "528959519\n",
      "511510779\n",
      "511510699\n",
      "Emx1-IRES-Cre\n",
      "527683915\n",
      "528544341\n",
      "530078243\n",
      "540168835\n",
      "526787625\n",
      "517328083\n",
      "530738229\n",
      "540650206\n",
      "536323956\n",
      "529676887\n",
      "528694719\n",
      "530688634\n",
      "528521086\n",
      "527676429\n",
      "527683915\n",
      "528544341\n",
      "530078243\n",
      "540168835\n",
      "526787625\n",
      "517328083\n",
      "530738229\n",
      "540650206\n",
      "536323956\n",
      "529676887\n",
      "528694719\n",
      "530688634\n",
      "528521086\n",
      "527676429\n",
      "Nr5a1-Cre\n",
      "532233174\n",
      "528792730\n",
      "539291370\n",
      "528799602\n",
      "531100608\n",
      "538803515\n",
      "529763300\n",
      "532233174\n",
      "528792730\n",
      "539291370\n",
      "528799602\n",
      "531100608\n",
      "538803515\n",
      "529763300\n",
      "Rbp4-Cre\n",
      "511510896\n",
      "511510758\n",
      "511510635\n",
      "511510974\n",
      "Rbp4-Cre_KL100\n",
      "511510896\n",
      "511510758\n",
      "511510635\n",
      "529770662\n",
      "511510974\n",
      "511510896\n",
      "511510758\n",
      "511510635\n",
      "529770662\n",
      "511510974\n",
      "Rorb-IRES2-Cre\n",
      "511506664\n",
      "511507144\n",
      "512124562\n",
      "511510675\n",
      "511510989\n",
      "530739574\n",
      "511506664\n",
      "511507144\n",
      "512124562\n",
      "511510675\n",
      "531823088\n",
      "526481129\n",
      "511510989\n",
      "530739574\n",
      "511506664\n",
      "511507144\n",
      "512124562\n",
      "511510675\n",
      "531823088\n",
      "526481129\n",
      "511510989\n",
      "Scnn1a-Tg3-Cre\n",
      "511510911\n",
      "511498742\n",
      "511510955\n",
      "511507811\n",
      "511510911\n",
      "528889127\n",
      "535575493\n",
      "540993888\n",
      "511498742\n",
      "511510955\n",
      "531134088\n",
      "511507811\n",
      "511510911\n",
      "528889127\n",
      "535575493\n",
      "540993888\n",
      "511498742\n",
      "511510955\n",
      "531134088\n",
      "511507811\n"
     ]
    }
   ],
   "source": [
    "['Cux2-CreERT2', 'Emx1-IRES-Cre', 'Nr5a1-Cre', 'Rbp4-Cre_KL100', 'Rorb-IRES2-Cre', 'Scnn1a-Tg3-Cre']\n",
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "\n",
    "sparsity_dict_cre = {}\n",
    "for cre_line in cre_lines:\n",
    "    print cre_line\n",
    "    container_list_filt = pd.DataFrame(boc.get_experiment_containers(targeted_structures=['VISp'],cre_lines=[cre_line]))\n",
    "\n",
    "    sparsity_dict_cre_container = {}\n",
    "    for ind in np.arange(len(container_list_filt)):\n",
    "        container_id = container_list_filt['id'].values[ind]  # This goes through the different mice\n",
    "\n",
    "        print container_id\n",
    "        \n",
    "        exp = boc.get_ophys_experiments(experiment_container_ids=[container_id], \n",
    "                                stimuli=[stim_info.NATURAL_SCENES])[0]\n",
    "        data_set = boc.get_ophys_experiment_data(exp['id'])\n",
    "        ns = NaturalScenes(data_set)\n",
    "        num_cells = np.shape(ns.response[:,:,0])[1]-1\n",
    "        \n",
    "        sprs_indk = []\n",
    "        sprs_indf = []\n",
    "        sprs_indv = []\n",
    "        for i in range(num_cells):\n",
    "            mean_over_image = np.squeeze(ns.response[:,i,0])\n",
    "            sprs_indk.append(get_indk(mean_over_image))\n",
    "            sprs_indv.append(get_indv(mean_over_image))\n",
    "\n",
    "        sparsity_dict_cre_container[container_id] = np.mean(sprs_indv)\n",
    "    sparsity_dict_cre[cre_line] = sparsity_dict_cre_container\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the data\n",
    "results_file='nat_scenes_v1_sparsity.pkl'\n",
    "f=open(results_file,\"wb\")\n",
    "cpickle.dump(sparsity_dict_cre, f,protocol=cpickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'Cux2-CreERT2': {511507650: 0.18879441972867581,\n",
       "  511509529: 0.17220893991399377,\n",
       "  511510650: 0.16729288034232098,\n",
       "  511510667: 0.17339939749484704,\n",
       "  511510670: 0.13930629970108852,\n",
       "  511510699: 0.13166060888023032,\n",
       "  511510718: 0.14865216177105287,\n",
       "  511510736: 0.15770049060086469,\n",
       "  511510779: 0.14756069740915759,\n",
       "  511510855: 0.12746066327765679,\n",
       "  511510884: 0.11268605283840158,\n",
       "  511510927: 0.12843519786769336,\n",
       "  524691282: 0.1020840336134454,\n",
       "  527550471: 0.097660959120490318,\n",
       "  528959519: 0.12308823529411766,\n",
       "  530243910: 0.10808275273157764},\n",
       " u'Emx1-IRES-Cre': {517328083: 0.13194630872483223,\n",
       "  526787625: 0.066922347886523056,\n",
       "  527676429: 0.13491912371885173,\n",
       "  527683915: 0.081274888333711867,\n",
       "  528521086: 0.13124891335844685,\n",
       "  528544341: 0.053646328096455996,\n",
       "  528694719: 0.11619047619047621,\n",
       "  529676887: 0.13228558264036688,\n",
       "  530078243: 0.12885257806826439,\n",
       "  530688634: 0.07938713416401047,\n",
       "  530738229: 0.13642038633635276,\n",
       "  536323956: 0.12490396158463388,\n",
       "  540168835: 0.1255542216886755,\n",
       "  540650206: 0.06500000000000003},\n",
       " u'Nr5a1-Cre': {528792730: 0.13321140220794203,\n",
       "  528799602: 0.089838396897220452,\n",
       "  529763300: 0.1553846153846154,\n",
       "  531100608: 0.12807132609141222,\n",
       "  532233174: 0.13065962668253145,\n",
       "  538803515: 0.14595874713521773,\n",
       "  539291370: 0.14272108843537423},\n",
       " u'Rbp4-Cre': {511510635: 0.12638184245660883,\n",
       "  511510758: 0.1358727794915435,\n",
       "  511510896: 0.17473389355742303,\n",
       "  511510974: 0.12386910319683431},\n",
       " u'Rbp4-Cre_KL100': {511510635: 0.12638184245660883,\n",
       "  511510758: 0.1358727794915435,\n",
       "  511510896: 0.17473389355742303,\n",
       "  511510974: 0.12386910319683431,\n",
       "  529770662: 0.10401989367175445},\n",
       " u'Rorb-IRES2-Cre': {511506664: 0.1454031529967359,\n",
       "  511507144: 0.19435802227867893,\n",
       "  511510675: 0.13594995893094083,\n",
       "  511510989: 0.15102323282254082,\n",
       "  512124562: 0.18325904274753382,\n",
       "  526481129: 0.09849470222871759,\n",
       "  530739574: 0.1680976820258305,\n",
       "  531823088: 0.12666666666666671},\n",
       " u'Scnn1a-Tg3-Cre': {511498742: 0.11861630088928779,\n",
       "  511507811: 0.13455230368009274,\n",
       "  511510911: 0.12306722689075633,\n",
       "  511510955: 0.12456837280366698,\n",
       "  528889127: 0.093915202444614237,\n",
       "  531134088: 0.10636808569581681,\n",
       "  535575493: 0.10600640256102446,\n",
       "  540993888: 0.15512605042016811}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity_dict_cre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
